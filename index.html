<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Using Transformers Locally</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <header>
        <nav>
            <div class="logo">Daniel K Baissa</div>
            <ul>
                <li><a href="#home">Home</a></li>
                <li><a href="#intro">Introduction</a></li>
                <li><a href="#chapters">Chapters</a></li>
                <li><a href="#resources">Resources</a></li>
            </ul>
        </nav>
        <div class="hero">
            <div class="hero-text">
                <h1>Using Transformers Locally</h1>
                <p>A simple guide to using transformer models on your machine!</p>
                <a href="#chapters" class="btn">Start Learning</a>
            </div>
            <div class="hero-image">
                <img src="An_illustration_of_a_transformer_model_used_in_nat.png" alt="Transformers Illustration">
            </div>
        </div>
    </header>

    <section id="intro">
        <h2>Introduction</h2>
        <p>Welcome to this guide on learning how to use transformer models locally. This guide will walk you through the fundamental concepts, setup, and practical applications of transformers in natural language processing (NLP).</p>
    </section>

    <section id="chapters">
        <h2>Chapters</h2>
        <div class="chapter">
            <h3>Chapter 1: Introduction to Learning Transformers</h3>
            <p>This chapter introduces the basics of transformer models and provides an overview of their applications in NLP.</p>
            <a href="https://danbaissa.github.io/NLP/Intro_Learning_Transformers" class="btn">Chapter 1</a>
        </div>
        <div class="chapter">
            <h3>Chapter 2: Text Classification with Transformers</h3>
            <p>This chapter covers text classification tasks using transformer models, demonstrating various NLP use cases.</p>
            <a href="https://danbaissa.github.io/NLP/Text_classification/Text_classification" class="btn">Chapter 2</a>
        </div>
        <div class="chapter">
            <h3>Chapter 3: Example - Detecting Hate Speech in Arabic</h3>
            <p>This chapter provides a practical example of using transformers to detect hate speech in Arabic text.</p>
            <a href="https://danbaissa.github.io/NLP/Example_Detecting_hatespeach_Arabic" class="btn">Chapter 3</a>
        </div>
            <div class="chapter">
            <h3>Chapter 4a: Looking into the Black Box (Part 1)</h3>
            <p>Transformer Models are often seen as black boxes. Here we visualize the attention mask to see the relations a model makes.</p>
            <a href="https://danbaissa.github.io/NLP/Visualizing_attention/Visualizing_attention" class="btn">Chapter 4a</a>
            <p></p>
            <h3>Chapter 4b: Looking into the Black Box (Part 2)</h3>
            <p>After visualizing the data in Part 1, we now extract the weights from a GPT model in Part 2, so we can learn how it makes its predictions.</p>
            <a href="https://danbaissa.github.io/NLP/Visualizing_attention/attention_weights" class="btn">Chapter 4b</a>
        </div>
        <div class="chapter">
            <h3>Chapter 5: Example - Mamba the Future of NLP?</h3>
            <p>Here we explore the Mamba model and compare it to an 8B transformer model.</p>
            <a href="https://danbaissa.github.io/NLP/Mamba/Mamba" class="btn">Chapter 5</a>
        </div>
        <div class="chapter">
            <h3>Chapter 6: Diagnosing Autism by Reading Simulated Doctors' Notes</h3>
            <p>In this project I develop a pipeline to help doctors diagnose autism by simply reading their notes.</p>
            <a href="https://danbaissa.github.io/NLP/Autism_Notes_Model_Training_and_SHAP_Explanation/Autism_Notes_Model_Training_and_SHAP_Explanation" class="btn">Chapter 6</a>
        </div>
    </section>

    <section id="resources">
        <h2>Resources</h2>
        <p>Here are some additional resources to help you deepen your understanding of transformer models:</p>
        <ul>
            <li><a href="https://github.com/huggingface/transformers">Hugging Face Transformers Library</a></li>
            <li><a href="https://arxiv.org/abs/1706.03762">Attention is All You Need (Original Paper)</a></li>
            <li><a href="https://www.tensorflow.org/tutorials/text/transformer">TensorFlow Transformer Tutorial</a></li>
        </ul>
    </section>

    <footer>
        <p>by Daniel K Baissa</p>
    </footer>
</body>

</html>
