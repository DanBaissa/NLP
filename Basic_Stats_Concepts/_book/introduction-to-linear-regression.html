<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Introduction to Linear Regression | Introduction to Basic Stats Concepts</title>
  <meta name="description" content="“Dive into the world of statistics with ‘Introduction to Basic Stats Concepts.’ This book is designed to demystify complex statistical topics and make them accessible to everyone. Whether you’re a student starting out, a professional looking to refresh your knowledge, or a curious mind eager to understand how data shapes our understanding of the world, this book is for you. Featuring practical examples, detailed explanations, and interactive R code snippets, this guide is your first step towards mastering the fundamentals of statistics. Join us as we explore everything from p-values to machine learning, all explained in a clear and engaging manner.”" />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Introduction to Linear Regression | Introduction to Basic Stats Concepts" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="“Dive into the world of statistics with ‘Introduction to Basic Stats Concepts.’ This book is designed to demystify complex statistical topics and make them accessible to everyone. Whether you’re a student starting out, a professional looking to refresh your knowledge, or a curious mind eager to understand how data shapes our understanding of the world, this book is for you. Featuring practical examples, detailed explanations, and interactive R code snippets, this guide is your first step towards mastering the fundamentals of statistics. Join us as we explore everything from p-values to machine learning, all explained in a clear and engaging manner.”" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Introduction to Linear Regression | Introduction to Basic Stats Concepts" />
  
  <meta name="twitter:description" content="“Dive into the world of statistics with ‘Introduction to Basic Stats Concepts.’ This book is designed to demystify complex statistical topics and make them accessible to everyone. Whether you’re a student starting out, a professional looking to refresh your knowledge, or a curious mind eager to understand how data shapes our understanding of the world, this book is for you. Featuring practical examples, detailed explanations, and interactive R code snippets, this guide is your first step towards mastering the fundamentals of statistics. Join us as we explore everything from p-values to machine learning, all explained in a clear and engaging manner.”" />
  

<meta name="author" content="Daniel K Baissa" />


<meta name="date" content="2024-06-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ab-testing-explained.html"/>
<link rel="next" href="diving-into-spatial-regression.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Basic Stats Concepts</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#welcome-to-our-statistical-journey"><i class="fa fa-check"></i><b>1.1</b> Welcome to Our Statistical Journey!</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#why-this-book"><i class="fa fa-check"></i><b>1.1.1</b> Why This Book?</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#what-will-you-learn"><i class="fa fa-check"></i><b>1.1.2</b> What Will You Learn?</a></li>
<li class="chapter" data-level="1.1.3" data-path="index.html"><a href="index.html#how-to-use-this-book"><i class="fa fa-check"></i><b>1.1.3</b> How to Use This Book</a></li>
<li class="chapter" data-level="1.1.4" data-path="index.html"><a href="index.html#a-note-of-caution"><i class="fa fa-check"></i><b>1.1.4</b> A Note of Caution</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#lets-get-started"><i class="fa fa-check"></i><b>1.2</b> Let’s Get Started!</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html"><i class="fa fa-check"></i><b>2</b> Exploring Probability Distributions with Visuals</a>
<ul>
<li class="chapter" data-level="2.1" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html#normal-distribution-the-bell"><i class="fa fa-check"></i><b>2.1</b> Normal Distribution: The Bell</a></li>
<li class="chapter" data-level="2.2" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html#binomial-distribution-counting-successes"><i class="fa fa-check"></i><b>2.2</b> Binomial Distribution: Counting Successes</a></li>
<li class="chapter" data-level="2.3" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html#poisson-distribution-counting-events"><i class="fa fa-check"></i><b>2.3</b> Poisson Distribution: Counting Events</a></li>
<li class="chapter" data-level="2.4" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html#negative-binomial-distribution-waiting-for-successes"><i class="fa fa-check"></i><b>2.4</b> Negative Binomial Distribution: Waiting for Successes</a></li>
<li class="chapter" data-level="2.5" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html#central-limit-theorem-what-happens-when-distributions-come-together"><i class="fa fa-check"></i><b>2.5</b> Central Limit Theorem: What Happens When Distributions Come Together?</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html#central-limit-theorem-in-r"><i class="fa fa-check"></i><b>2.5.1</b> Central Limit Theorem in R</a></li>
<li class="chapter" data-level="2.5.2" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html#whats-happening-here"><i class="fa fa-check"></i><b>2.5.2</b> What’s Happening Here?</a></li>
<li class="chapter" data-level="2.5.3" data-path="exploring-probability-distributions-with-visuals.html"><a href="exploring-probability-distributions-with-visuals.html#implications"><i class="fa fa-check"></i><b>2.5.3</b> Implications</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html"><i class="fa fa-check"></i><b>3</b> Understanding the p-value</a>
<ul>
<li class="chapter" data-level="3.1" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#what-is-a-p-value"><i class="fa fa-check"></i><b>3.1</b> What is a p-value?</a></li>
<li class="chapter" data-level="3.2" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#visualizing-p-values-how-sigma-frames-our-understanding"><i class="fa fa-check"></i><b>3.2</b> Visualizing p-values: How Sigma Frames Our Understanding</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#the-concept-of-sigma"><i class="fa fa-check"></i><b>3.2.1</b> The Concept of Sigma</a></li>
<li class="chapter" data-level="3.2.2" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#the-plot-of-sigma-and-p-values"><i class="fa fa-check"></i><b>3.2.2</b> The Plot of Sigma and p-values</a></li>
<li class="chapter" data-level="3.2.3" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#whats-going-on-here"><i class="fa fa-check"></i><b>3.2.3</b> What’s Going on Here?</a></li>
<li class="chapter" data-level="3.2.4" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#takeaway"><i class="fa fa-check"></i><b>3.2.4</b> Takeaway</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#exploring-p-values-through-simulation"><i class="fa fa-check"></i><b>3.3</b> Exploring p-values through Simulation</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#simulating-multiple-t-tests"><i class="fa fa-check"></i><b>3.3.1</b> Simulating Multiple t-tests</a></li>
<li class="chapter" data-level="3.3.2" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#whats-happening-here-1"><i class="fa fa-check"></i><b>3.3.2</b> What’s Happening Here?</a></li>
<li class="chapter" data-level="3.3.3" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#insights-from-the-simulation"><i class="fa fa-check"></i><b>3.3.3</b> Insights from the Simulation</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#false-positives-and-false-negatives"><i class="fa fa-check"></i><b>3.4</b> False Positives and False Negatives</a></li>
<li class="chapter" data-level="3.5" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#understanding-power-through-elephants"><i class="fa fa-check"></i><b>3.5</b> Understanding Power Through Elephants</a></li>
<li class="chapter" data-level="3.6" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#beyond-p-values-the-importance-of-substantive-significance"><i class="fa fa-check"></i><b>3.6</b> Beyond p-values: The Importance of Substantive Significance</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="understanding-the-p-value.html"><a href="understanding-the-p-value.html#example-water-vs.-cyanide"><i class="fa fa-check"></i><b>3.6.1</b> Example: Water vs. Cyanide</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="dive-into-the-t-test.html"><a href="dive-into-the-t-test.html"><i class="fa fa-check"></i><b>4</b> Dive into the t-test</a>
<ul>
<li class="chapter" data-level="4.1" data-path="dive-into-the-t-test.html"><a href="dive-into-the-t-test.html#basics-of-the-t-test"><i class="fa fa-check"></i><b>4.1</b> Basics of the t-test</a></li>
<li class="chapter" data-level="4.2" data-path="dive-into-the-t-test.html"><a href="dive-into-the-t-test.html#step-by-step-example-using-simulated-data"><i class="fa fa-check"></i><b>4.2</b> Step-by-Step Example Using Simulated Data</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="dive-into-the-t-test.html"><a href="dive-into-the-t-test.html#setting-up-the-problem"><i class="fa fa-check"></i><b>4.2.1</b> Setting Up the Problem</a></li>
<li class="chapter" data-level="4.2.2" data-path="dive-into-the-t-test.html"><a href="dive-into-the-t-test.html#performing-an-independent-samples-t-test"><i class="fa fa-check"></i><b>4.2.2</b> Performing an Independent Samples t-test</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="dive-into-the-t-test.html"><a href="dive-into-the-t-test.html#interpreting-results"><i class="fa fa-check"></i><b>4.3</b> Interpreting Results</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ab-testing-explained.html"><a href="ab-testing-explained.html"><i class="fa fa-check"></i><b>5</b> A/B Testing Explained</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ab-testing-explained.html"><a href="ab-testing-explained.html#what-is-ab-testing"><i class="fa fa-check"></i><b>5.1</b> What is A/B Testing?</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="ab-testing-explained.html"><a href="ab-testing-explained.html#running-an-ab-test"><i class="fa fa-check"></i><b>5.1.1</b> Running an A/B Test</a></li>
<li class="chapter" data-level="5.1.2" data-path="ab-testing-explained.html"><a href="ab-testing-explained.html#example-scenario"><i class="fa fa-check"></i><b>5.1.2</b> Example Scenario</a></li>
<li class="chapter" data-level="5.1.3" data-path="ab-testing-explained.html"><a href="ab-testing-explained.html#implementing-in-r"><i class="fa fa-check"></i><b>5.1.3</b> Implementing in R</a></li>
<li class="chapter" data-level="5.1.4" data-path="ab-testing-explained.html"><a href="ab-testing-explained.html#analyzing-results"><i class="fa fa-check"></i><b>5.1.4</b> Analyzing Results</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="ab-testing-explained.html"><a href="ab-testing-explained.html#considerations-and-best-practices"><i class="fa fa-check"></i><b>5.2</b> Considerations and Best Practices</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html"><i class="fa fa-check"></i><b>6</b> Introduction to Linear Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#the-concept"><i class="fa fa-check"></i><b>6.1</b> The Concept</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#visualizing-simple-attempts"><i class="fa fa-check"></i><b>6.1.1</b> Visualizing Simple Attempts</a></li>
<li class="chapter" data-level="6.1.2" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#finding-the-best-fit"><i class="fa fa-check"></i><b>6.1.2</b> Finding the Best Fit</a></li>
<li class="chapter" data-level="6.1.3" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#understanding-the-model"><i class="fa fa-check"></i><b>6.1.3</b> Understanding the Model</a></li>
<li class="chapter" data-level="6.1.4" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#going-a-step-further-linear-algebra"><i class="fa fa-check"></i><b>6.1.4</b> Going a Step Further: Linear Algebra</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#assumptions-of-linear-regression"><i class="fa fa-check"></i><b>6.2</b> Assumptions of Linear Regression</a></li>
<li class="chapter" data-level="6.3" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#extending-linear-regression"><i class="fa fa-check"></i><b>6.3</b> Extending Linear Regression</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#spatial-regression"><i class="fa fa-check"></i><b>6.3.1</b> Spatial Regression</a></li>
<li class="chapter" data-level="6.3.2" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#robust-estimation"><i class="fa fa-check"></i><b>6.3.2</b> Robust Estimation</a></li>
<li class="chapter" data-level="6.3.3" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#robust-standard-errors"><i class="fa fa-check"></i><b>6.3.3</b> Robust Standard Errors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="diving-into-spatial-regression.html"><a href="diving-into-spatial-regression.html"><i class="fa fa-check"></i><b>7</b> Diving into Spatial Regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="diving-into-spatial-regression.html"><a href="diving-into-spatial-regression.html#why-not-just-use-ordinary-regression"><i class="fa fa-check"></i><b>7.1</b> Why Not Just Use Ordinary Regression?</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="diving-into-spatial-regression.html"><a href="diving-into-spatial-regression.html#introducing-spatial-regression"><i class="fa fa-check"></i><b>7.1.1</b> Introducing Spatial Regression</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="diving-into-spatial-regression.html"><a href="diving-into-spatial-regression.html#key-concepts-in-spatial-regression"><i class="fa fa-check"></i><b>7.2</b> Key Concepts in Spatial Regression</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="diving-into-spatial-regression.html"><a href="diving-into-spatial-regression.html#why-does-this-matter"><i class="fa fa-check"></i><b>7.2.1</b> Why Does This Matter?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><i class="fa fa-check"></i><b>8</b> Robust Estimation: Dealing with Outliers and Heavy Tails</a>
<ul>
<li class="chapter" data-level="8.1" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#why-robust-estimation"><i class="fa fa-check"></i><b>8.1</b> Why Robust Estimation?</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#m-estimators-a-closer-look"><i class="fa fa-check"></i><b>8.1.1</b> M Estimators: A Closer Look</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#commonly-used-weight-functions"><i class="fa fa-check"></i><b>8.2</b> Commonly Used Weight Functions:</a></li>
<li class="chapter" data-level="8.3" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#mm-estimators-enhancing-robustness"><i class="fa fa-check"></i><b>8.3</b> MM Estimators: Enhancing Robustness</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#simulation-and-analysis-in-r"><i class="fa fa-check"></i><b>8.3.1</b> Simulation and Analysis in R</a></li>
<li class="chapter" data-level="8.3.2" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#observations-from-the-simulation"><i class="fa fa-check"></i><b>8.3.2</b> Observations from the Simulation</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#how-robust-is-robust"><i class="fa fa-check"></i><b>8.4</b> How Robust is Robust?</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#simulation-setup"><i class="fa fa-check"></i><b>8.4.1</b> Simulation Setup</a></li>
<li class="chapter" data-level="8.4.2" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#observations-from-the-plot"><i class="fa fa-check"></i><b>8.4.2</b> Observations from the Plot</a></li>
<li class="chapter" data-level="8.4.3" data-path="robust-estimation-dealing-with-outliers-and-heavy-tails.html"><a href="robust-estimation-dealing-with-outliers-and-heavy-tails.html#conclusion"><i class="fa fa-check"></i><b>8.4.3</b> Conclusion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html"><i class="fa fa-check"></i><b>9</b> Robust Standard Errors: Tackling Heteroscedasticity</a>
<ul>
<li class="chapter" data-level="9.1" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#visualizing-heteroscedasticity"><i class="fa fa-check"></i><b>9.1</b> Visualizing Heteroscedasticity</a></li>
<li class="chapter" data-level="9.2" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#addressing-heteroscedasticity-with-robust-standard-errors"><i class="fa fa-check"></i><b>9.2</b> Addressing Heteroscedasticity with Robust Standard Errors</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#observations-from-the-analysis"><i class="fa fa-check"></i><b>9.2.1</b> Observations from the Analysis</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#math-behind-robust-standard-errors"><i class="fa fa-check"></i><b>9.3</b> Math Behind Robust Standard Errors</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#basic-formulation"><i class="fa fa-check"></i><b>9.3.1</b> Basic Formulation</a></li>
<li class="chapter" data-level="9.3.2" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#robust-standard-errors-1"><i class="fa fa-check"></i><b>9.3.2</b> Robust Standard Errors</a></li>
<li class="chapter" data-level="9.3.3" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#heteroscedasticity-consistent-estimators-hc"><i class="fa fa-check"></i><b>9.3.3</b> Heteroscedasticity-Consistent Estimators (HC)</a></li>
<li class="chapter" data-level="9.3.4" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#choosing-the-right-estimator"><i class="fa fa-check"></i><b>9.3.4</b> Choosing the Right Estimator</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#implementing-in-r-1"><i class="fa fa-check"></i><b>9.4</b> Implementing in R</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="robust-standard-errors-tackling-heteroscedasticity.html"><a href="robust-standard-errors-tackling-heteroscedasticity.html#ending-thoughts"><i class="fa fa-check"></i><b>9.4.1</b> Ending Thoughts</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="going-beyond-linear-regression-introduction-to-logistic-regression.html"><a href="going-beyond-linear-regression-introduction-to-logistic-regression.html"><i class="fa fa-check"></i><b>10</b> Going Beyond Linear Regression: Introduction to Logistic Regression</a>
<ul>
<li class="chapter" data-level="10.1" data-path="going-beyond-linear-regression-introduction-to-logistic-regression.html"><a href="going-beyond-linear-regression-introduction-to-logistic-regression.html#why-use-logistic-regression"><i class="fa fa-check"></i><b>10.1</b> Why Use Logistic Regression?</a></li>
<li class="chapter" data-level="10.2" data-path="going-beyond-linear-regression-introduction-to-logistic-regression.html"><a href="going-beyond-linear-regression-introduction-to-logistic-regression.html#the-logistic-function"><i class="fa fa-check"></i><b>10.2</b> The Logistic Function</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="going-beyond-linear-regression-introduction-to-logistic-regression.html"><a href="going-beyond-linear-regression-introduction-to-logistic-regression.html#visualizing-the-sigmoid-function"><i class="fa fa-check"></i><b>10.2.1</b> Visualizing the Sigmoid Function</a></li>
<li class="chapter" data-level="10.2.2" data-path="going-beyond-linear-regression-introduction-to-logistic-regression.html"><a href="going-beyond-linear-regression-introduction-to-logistic-regression.html#what-does-this-plot-show"><i class="fa fa-check"></i><b>10.2.2</b> What Does This Plot Show?</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="going-beyond-linear-regression-introduction-to-logistic-regression.html"><a href="going-beyond-linear-regression-introduction-to-logistic-regression.html#demonstration-in-r"><i class="fa fa-check"></i><b>10.3</b> Demonstration in R</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html"><i class="fa fa-check"></i><b>11</b> Introduction to K-Means Clustering</a>
<ul>
<li class="chapter" data-level="11.1" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html#why-k-means-clustering"><i class="fa fa-check"></i><b>11.1</b> Why K-Means Clustering?</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html#how-does-k-means-work"><i class="fa fa-check"></i><b>11.1.1</b> How Does K-Means Work?</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html#practical-example-k-means-on-the-iris-dataset"><i class="fa fa-check"></i><b>11.2</b> Practical Example: K-Means on the Iris Dataset</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html#visualizing-k-means-clustering"><i class="fa fa-check"></i><b>11.2.1</b> Visualizing K-Means Clustering</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html#the-math-of-k-means-clustering-getting-the-grouping-right"><i class="fa fa-check"></i><b>11.3</b> The Math of K-Means Clustering: Getting the Grouping Right</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html#the-math-behind-perfect-grouping"><i class="fa fa-check"></i><b>11.3.1</b> The Math Behind Perfect Grouping</a></li>
<li class="chapter" data-level="11.3.2" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html#how-k-means-tidies-up"><i class="fa fa-check"></i><b>11.3.2</b> How K-Means Tidies Up</a></li>
<li class="chapter" data-level="11.3.3" data-path="introduction-to-k-means-clustering.html"><a href="introduction-to-k-means-clustering.html#why-do-we-care"><i class="fa fa-check"></i><b>11.3.3</b> Why Do We Care?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html"><i class="fa fa-check"></i><b>12</b> Introduction to Machine Learning: Random Forests</a>
<ul>
<li class="chapter" data-level="12.1" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#why-random-forests"><i class="fa fa-check"></i><b>12.1</b> Why Random Forests?</a></li>
<li class="chapter" data-level="12.2" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#understanding-random-forests-by-starting-with-a-single-tree"><i class="fa fa-check"></i><b>12.2</b> Understanding Random Forests by Starting with a Single Tree</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#how-are-splits-determined"><i class="fa fa-check"></i><b>12.2.1</b> How are Splits Determined?</a></li>
<li class="chapter" data-level="12.2.2" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#example-decision-tree-with-the-iris-dataset"><i class="fa fa-check"></i><b>12.2.2</b> Example: Decision Tree with the Iris Dataset</a></li>
<li class="chapter" data-level="12.2.3" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#visualizing-the-decision-tree"><i class="fa fa-check"></i><b>12.2.3</b> Visualizing the Decision Tree</a></li>
<li class="chapter" data-level="12.2.4" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#decision-tree-insights"><i class="fa fa-check"></i><b>12.2.4</b> Decision Tree Insights</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#step-by-step-example-with-random-forests"><i class="fa fa-check"></i><b>12.3</b> Step-by-Step Example with Random Forests</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#setting-up-the-problem-2"><i class="fa fa-check"></i><b>12.3.1</b> Setting Up the Problem</a></li>
<li class="chapter" data-level="12.3.2" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#visualizing-the-ensemble-effect"><i class="fa fa-check"></i><b>12.3.2</b> Visualizing the Ensemble Effect</a></li>
<li class="chapter" data-level="12.3.3" data-path="introduction-to-machine-learning-random-forests.html"><a href="introduction-to-machine-learning-random-forests.html#using-the-model"><i class="fa fa-check"></i><b>12.3.3</b> Using the Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="wrapping-up-fun-with-numbers.html"><a href="wrapping-up-fun-with-numbers.html"><i class="fa fa-check"></i><b>13</b> Wrapping Up: Fun with Numbers</a>
<ul>
<li class="chapter" data-level="13.1" data-path="wrapping-up-fun-with-numbers.html"><a href="wrapping-up-fun-with-numbers.html#embrace-the-power-use-it-wisely"><i class="fa fa-check"></i><b>13.1</b> Embrace the Power, Use it Wisely</a></li>
<li class="chapter" data-level="13.2" data-path="wrapping-up-fun-with-numbers.html"><a href="wrapping-up-fun-with-numbers.html#the-cautionary-note"><i class="fa fa-check"></i><b>13.2</b> The Cautionary Note</a></li>
<li class="chapter" data-level="13.3" data-path="wrapping-up-fun-with-numbers.html"><a href="wrapping-up-fun-with-numbers.html#stay-curious"><i class="fa fa-check"></i><b>13.3</b> Stay Curious!</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Basic Stats Concepts</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction-to-linear-regression" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Chapter 6</span> Introduction to Linear Regression<a href="introduction-to-linear-regression.html#introduction-to-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Linear regression might sound complex, but let’s break it down to something as simple as fitting a line through a set of points, just like you might have done in middle school. Remember the equation <span class="math inline">\(y = mx + b\)</span>? We’re going to start there. Remember m is the slope, and b is the intercept? Well, all regression does is solve for that using your data!</p>
<div id="the-concept" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> The Concept<a href="introduction-to-linear-regression.html#the-concept" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In statistical terms, this line equation becomes <span class="math inline">\(y = \alpha + \beta \times x + \epsilon\)</span>, where:</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> (alpha) is the y-intercept,</li>
<li><span class="math inline">\(\beta\)</span> (beta) is the slope of the line,</li>
<li><span class="math inline">\(\epsilon\)</span> (epsilon) or the error is the difference between the predicted values and the actual values.</li>
</ul>
<div id="visualizing-simple-attempts" class="section level3 hasAnchor" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> Visualizing Simple Attempts<a href="introduction-to-linear-regression.html#visualizing-simple-attempts" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s imagine a “Dan Estimator” and “Steve Estimator” are trying to draw a line through some data points. Both are pretty bad at it. Their lines don’t really capture the trend of the data.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="introduction-to-linear-regression.html#cb15-1" tabindex="-1"></a><span class="co"># Simulate some data</span></span>
<span id="cb15-2"><a href="introduction-to-linear-regression.html#cb15-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb15-3"><a href="introduction-to-linear-regression.html#cb15-3" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span></span>
<span id="cb15-4"><a href="introduction-to-linear-regression.html#cb15-4" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span>x <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">mean=</span><span class="dv">0</span>, <span class="at">sd=</span><span class="dv">20</span>)  <span class="co"># true line: y = 2x + noise</span></span>
<span id="cb15-5"><a href="introduction-to-linear-regression.html#cb15-5" tabindex="-1"></a><span class="fu">plot</span>(x, y, <span class="at">main =</span> <span class="st">&quot;Fitting Lines: Dan vs. Steve&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;X&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Y&quot;</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb15-6"><a href="introduction-to-linear-regression.html#cb15-6" tabindex="-1"></a></span>
<span id="cb15-7"><a href="introduction-to-linear-regression.html#cb15-7" tabindex="-1"></a><span class="co"># Dan&#39;s and Steve&#39;s poor attempts</span></span>
<span id="cb15-8"><a href="introduction-to-linear-regression.html#cb15-8" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="dv">4</span><span class="sc">*</span>x <span class="sc">-</span> <span class="dv">40</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)  <span class="co"># Dan&#39;s line</span></span>
<span id="cb15-9"><a href="introduction-to-linear-regression.html#cb15-9" tabindex="-1"></a><span class="fu">lines</span>(x, .<span class="dv">5</span><span class="sc">*</span>x <span class="sc">+</span> <span class="dv">30</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)  <span class="co"># Steve&#39;s line</span></span>
<span id="cb15-10"><a href="introduction-to-linear-regression.html#cb15-10" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;Dan&quot;</span>, <span class="st">&quot;Steve&quot;</span>), <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>), <span class="at">lty=</span><span class="dv">1</span>, <span class="at">cex=</span><span class="fl">0.8</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-82-1.png" width="672" /></p>
</div>
<div id="finding-the-best-fit" class="section level3 hasAnchor" number="6.1.2">
<h3><span class="header-section-number">6.1.2</span> Finding the Best Fit<a href="introduction-to-linear-regression.html#finding-the-best-fit" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, while Dan and Steve’s attempts are entertaining, they’re obviously not ideal. Maybe we want an estimator that draws a line right through the middle of these points? One that minimizes the distance from all points to the line itself. How can we ensure it’s the best fit?</p>
<div id="introducing-least-squares" class="section level4 hasAnchor" number="6.1.2.1">
<h4><span class="header-section-number">6.1.2.1</span> Introducing Least Squares<a href="introduction-to-linear-regression.html#introducing-least-squares" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We want to fit a line through the middle one where we minimize the distance from the line to the points on average. In otherwords we aim to minimize the sum of the squared distances (squared errors) from the data points to the regression line. This method is called “least squares.”</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="introduction-to-linear-regression.html#cb16-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb16-2"><a href="introduction-to-linear-regression.html#cb16-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span></span>
<span id="cb16-3"><a href="introduction-to-linear-regression.html#cb16-3" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span>x <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">mean=</span><span class="dv">0</span>, <span class="at">sd=</span><span class="dv">20</span>)</span>
<span id="cb16-4"><a href="introduction-to-linear-regression.html#cb16-4" tabindex="-1"></a></span>
<span id="cb16-5"><a href="introduction-to-linear-regression.html#cb16-5" tabindex="-1"></a><span class="co"># Fitting a regression line</span></span>
<span id="cb16-6"><a href="introduction-to-linear-regression.html#cb16-6" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb16-7"><a href="introduction-to-linear-regression.html#cb16-7" tabindex="-1"></a></span>
<span id="cb16-8"><a href="introduction-to-linear-regression.html#cb16-8" tabindex="-1"></a><span class="co"># true line: y = 2x + noise</span></span>
<span id="cb16-9"><a href="introduction-to-linear-regression.html#cb16-9" tabindex="-1"></a><span class="fu">plot</span>(x, y, <span class="at">main =</span> <span class="st">&quot;Fitting Lines: Dan vs. Steve vs. Least Squares&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;X&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Y&quot;</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb16-10"><a href="introduction-to-linear-regression.html#cb16-10" tabindex="-1"></a></span>
<span id="cb16-11"><a href="introduction-to-linear-regression.html#cb16-11" tabindex="-1"></a><span class="co"># Dan&#39;s and Steve&#39;s poor attempts</span></span>
<span id="cb16-12"><a href="introduction-to-linear-regression.html#cb16-12" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="dv">4</span><span class="sc">*</span>x <span class="sc">-</span> <span class="dv">40</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)  <span class="co"># Dan&#39;s line</span></span>
<span id="cb16-13"><a href="introduction-to-linear-regression.html#cb16-13" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="fl">0.5</span><span class="sc">*</span>x <span class="sc">+</span> <span class="dv">30</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)  <span class="co"># Steve&#39;s line</span></span>
<span id="cb16-14"><a href="introduction-to-linear-regression.html#cb16-14" tabindex="-1"></a><span class="fu">abline</span>(fit, <span class="at">col=</span><span class="st">&quot;black&quot;</span>)  <span class="co"># adding the least squares line</span></span>
<span id="cb16-15"><a href="introduction-to-linear-regression.html#cb16-15" tabindex="-1"></a></span>
<span id="cb16-16"><a href="introduction-to-linear-regression.html#cb16-16" tabindex="-1"></a><span class="co"># Adding residuals for the least squares line</span></span>
<span id="cb16-17"><a href="introduction-to-linear-regression.html#cb16-17" tabindex="-1"></a>predicted_values <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit)</span>
<span id="cb16-18"><a href="introduction-to-linear-regression.html#cb16-18" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(x)) {</span>
<span id="cb16-19"><a href="introduction-to-linear-regression.html#cb16-19" tabindex="-1"></a>    <span class="fu">lines</span>(<span class="fu">c</span>(x[i], x[i]), <span class="fu">c</span>(y[i], predicted_values[i]), <span class="at">col=</span><span class="st">&quot;black&quot;</span>)</span>
<span id="cb16-20"><a href="introduction-to-linear-regression.html#cb16-20" tabindex="-1"></a>}</span>
<span id="cb16-21"><a href="introduction-to-linear-regression.html#cb16-21" tabindex="-1"></a></span>
<span id="cb16-22"><a href="introduction-to-linear-regression.html#cb16-22" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;Dan&quot;</span>, <span class="st">&quot;Steve&quot;</span>, <span class="st">&quot;Least Squares&quot;</span>), <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;black&quot;</span>), <span class="at">lty=</span><span class="dv">1</span>, <span class="at">cex=</span><span class="fl">0.8</span>)</span>
<span id="cb16-23"><a href="introduction-to-linear-regression.html#cb16-23" tabindex="-1"></a></span>
<span id="cb16-24"><a href="introduction-to-linear-regression.html#cb16-24" tabindex="-1"></a></span>
<span id="cb16-25"><a href="introduction-to-linear-regression.html#cb16-25" tabindex="-1"></a><span class="co"># Add a legend for the residuals</span></span>
<span id="cb16-26"><a href="introduction-to-linear-regression.html#cb16-26" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>, <span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;Residuals&quot;</span>), <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;black&quot;</span>), <span class="at">lty=</span><span class="dv">1</span>, <span class="at">cex=</span><span class="fl">0.8</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-83-1.png" width="672" /></p>
<p>Here we can see that the Least Squares line goes right through the middle and on average the distance from the line, the “residuals” are about the same on top as they are on the bottom.</p>
</div>
</div>
<div id="understanding-the-model" class="section level3 hasAnchor" number="6.1.3">
<h3><span class="header-section-number">6.1.3</span> Understanding the Model<a href="introduction-to-linear-regression.html#understanding-the-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The regression equation can be written as:
<span class="math display">\[ y = \alpha + \beta \times x + error\]</span>
where <span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\beta}\)</span> are estimates of the intercept and slope, determined by the least squares method.</p>
</div>
<div id="going-a-step-further-linear-algebra" class="section level3 hasAnchor" number="6.1.4">
<h3><span class="header-section-number">6.1.4</span> Going a Step Further: Linear Algebra<a href="introduction-to-linear-regression.html#going-a-step-further-linear-algebra" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For those interested in the mathematical details, the coefficients <span class="math inline">\(\beta\)</span> can also be estimated using linear algebra. This is expressed as:
<span class="math display">\[ \beta = (X^TX)^{-1}X^TY \]</span>
where <span class="math inline">\(X\)</span> is the matrix of input values, and <span class="math inline">\(Y\)</span> is the vector of output values. This formula provides the least squares estimates of the coefficients.</p>
<p>Let’s take the <code>cars</code> dataset, which contains two variables: <code>speed</code> (the speed of cars) and <code>dist</code> (the distance required to stop). We’ll predict <code>dist</code> based on <code>speed</code> using linear algebra.</p>
<div id="load-and-prepare-data" class="section level4 hasAnchor" number="6.1.4.1">
<h4><span class="header-section-number">6.1.4.1</span> Load and Prepare Data<a href="introduction-to-linear-regression.html#load-and-prepare-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>First, let’s load the data and prepare the matrices.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="introduction-to-linear-regression.html#cb17-1" tabindex="-1"></a><span class="co"># Load the dataset</span></span>
<span id="cb17-2"><a href="introduction-to-linear-regression.html#cb17-2" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb17-3"><a href="introduction-to-linear-regression.html#cb17-3" tabindex="-1"></a></span>
<span id="cb17-4"><a href="introduction-to-linear-regression.html#cb17-4" tabindex="-1"></a><span class="co"># Prepare the data matrix X (with intercept) and response vector Y</span></span>
<span id="cb17-5"><a href="introduction-to-linear-regression.html#cb17-5" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">cbind</span>(<span class="at">Intercept =</span> <span class="dv">1</span>, <span class="st">`</span><span class="at">Weight (1000 lbs)</span><span class="st">`</span> <span class="ot">=</span> mtcars<span class="sc">$</span>wt, <span class="st">`</span><span class="at">Displacement (cu.in.)</span><span class="st">`</span> <span class="ot">=</span> mtcars<span class="sc">$</span>disp, <span class="st">`</span><span class="at">Horsepower</span><span class="st">`</span> <span class="ot">=</span> mtcars<span class="sc">$</span>hp, <span class="st">`</span><span class="at">Number of cylinders</span><span class="st">`</span> <span class="ot">=</span> mtcars<span class="sc">$</span>cyl))  <span class="co"># Adding an intercept</span></span>
<span id="cb17-6"><a href="introduction-to-linear-regression.html#cb17-6" tabindex="-1"></a>Y <span class="ot">&lt;-</span> mtcars<span class="sc">$</span>mpg</span>
<span id="cb17-7"><a href="introduction-to-linear-regression.html#cb17-7" tabindex="-1"></a></span>
<span id="cb17-8"><a href="introduction-to-linear-regression.html#cb17-8" tabindex="-1"></a><span class="co"># Display the first few rows of X and Y</span></span>
<span id="cb17-9"><a href="introduction-to-linear-regression.html#cb17-9" tabindex="-1"></a><span class="fu">head</span>(X)</span></code></pre></div>
<pre><code>##      Intercept Weight (1000 lbs) Displacement (cu.in.) Horsepower Number of cylinders
## [1,]         1             2.620                   160        110                   6
## [2,]         1             2.875                   160        110                   6
## [3,]         1             2.320                   108         93                   4
## [4,]         1             3.215                   258        110                   6
## [5,]         1             3.440                   360        175                   8
## [6,]         1             3.460                   225        105                   6</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="introduction-to-linear-regression.html#cb19-1" tabindex="-1"></a><span class="fu">head</span>(Y)</span></code></pre></div>
<pre><code>## [1] 21.0 21.0 22.8 21.4 18.7 18.1</code></pre>
</div>
<div id="apply-the-linear-algebra-formula-for-beta" class="section level4 hasAnchor" number="6.1.4.2">
<h4><span class="header-section-number">6.1.4.2</span> Apply the Linear Algebra Formula for Beta<a href="introduction-to-linear-regression.html#apply-the-linear-algebra-formula-for-beta" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Now, we apply the linear algebra formula to compute the coefficients. The formula <span class="math inline">\(\beta = (X^TX)^{-1}X^TY\)</span> will give us the estimates for the intercept and the coefficient for <code>speed</code>.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="introduction-to-linear-regression.html#cb21-1" tabindex="-1"></a><span class="co"># Compute (X&#39;X)^(-1)</span></span>
<span id="cb21-2"><a href="introduction-to-linear-regression.html#cb21-2" tabindex="-1"></a>XTX_inv <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X)</span>
<span id="cb21-3"><a href="introduction-to-linear-regression.html#cb21-3" tabindex="-1"></a></span>
<span id="cb21-4"><a href="introduction-to-linear-regression.html#cb21-4" tabindex="-1"></a><span class="co"># Compute beta = (X&#39;X)^(-1)X&#39;Y</span></span>
<span id="cb21-5"><a href="introduction-to-linear-regression.html#cb21-5" tabindex="-1"></a>beta <span class="ot">&lt;-</span> XTX_inv <span class="sc">%*%</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> Y</span>
<span id="cb21-6"><a href="introduction-to-linear-regression.html#cb21-6" tabindex="-1"></a></span>
<span id="cb21-7"><a href="introduction-to-linear-regression.html#cb21-7" tabindex="-1"></a><span class="co"># Print the estimated coefficients</span></span>
<span id="cb21-8"><a href="introduction-to-linear-regression.html#cb21-8" tabindex="-1"></a>beta</span></code></pre></div>
<pre><code>##                              [,1]
## Intercept             40.82853674
## Weight (1000 lbs)     -3.85390352
## Displacement (cu.in.)  0.01159924
## Horsepower            -0.02053838
## Number of cylinders   -1.29331972</code></pre>
<p>This isn’t as pretty but check that out! Let’s just compare it to the built in lm function:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="introduction-to-linear-regression.html#cb23-1" tabindex="-1"></a>cars <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> wt <span class="sc">+</span> disp <span class="sc">+</span> hp <span class="sc">+</span> cyl, <span class="at">data =</span> mtcars)</span>
<span id="cb23-2"><a href="introduction-to-linear-regression.html#cb23-2" tabindex="-1"></a><span class="fu">summary</span>(cars)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt + disp + hp + cyl, data = mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.0562 -1.4636 -0.4281  1.2854  5.8269 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 40.82854    2.75747  14.807 1.76e-14 ***
## wt          -3.85390    1.01547  -3.795 0.000759 ***
## disp         0.01160    0.01173   0.989 0.331386    
## hp          -0.02054    0.01215  -1.691 0.102379    
## cyl         -1.29332    0.65588  -1.972 0.058947 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.513 on 27 degrees of freedom
## Multiple R-squared:  0.8486, Adjusted R-squared:  0.8262 
## F-statistic: 37.84 on 4 and 27 DF,  p-value: 1.061e-10</code></pre>
<p>Math works! In all seriousness though computers are much faster at solving <span class="math inline">\(\beta = (X^TX)^{-1}X^TY\)</span> than running that function, so if you are computing many <span class="math inline">\(\beta\)</span>s at once, it can come in handy.</p>
</div>
</div>
</div>
<div id="assumptions-of-linear-regression" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Assumptions of Linear Regression<a href="introduction-to-linear-regression.html#assumptions-of-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To effectively use linear regression, it’s essential to understand its underlying assumptions. If these assumptions are violated, the results might not be reliable. Here are the key assumptions:</p>
<ol style="list-style-type: decimal">
<li><strong>Linearity:</strong> The relationship between the predictors and the dependent variable is linear.</li>
<li><strong>Independence:</strong> Observations are independent of each other.</li>
<li><strong>Homoscedasticity:</strong> The variance of residual is the same for any value of the input variables.</li>
<li><strong>Normality:</strong> For any fixed value of the predictors, the dependent variable is normally distributed.</li>
</ol>
<p>Addressing these assumptions ensures the validity of the regression results. When these assumptions are not met, modifications and more advanced techniques might be necessary.</p>
</div>
<div id="extending-linear-regression" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Extending Linear Regression<a href="introduction-to-linear-regression.html#extending-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As powerful as linear regression is, it sometimes needs to be adjusted or extended to handle more complex data characteristics. Here are a few notable extensions:</p>
<div id="spatial-regression" class="section level3 hasAnchor" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> Spatial Regression<a href="introduction-to-linear-regression.html#spatial-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When dealing with geographical or spatial data, traditional regression might not suffice because observations in close proximity might be correlated, violating the independence assumption. Spatial regression models account for this correlation, offering more precise insights for geographical data analysis.</p>
</div>
<div id="robust-estimation" class="section level3 hasAnchor" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> Robust Estimation<a href="introduction-to-linear-regression.html#robust-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Robust estimators are a broad class of estimators that generalize the method of least squares. They are particularly useful when dealing with outliers or heavy-tailed distributions, as they provide robustness against violations of the normality assumption.</p>
</div>
<div id="robust-standard-errors" class="section level3 hasAnchor" number="6.3.3">
<h3><span class="header-section-number">6.3.3</span> Robust Standard Errors<a href="introduction-to-linear-regression.html#robust-standard-errors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Robust standard errors are an adjustment to standard errors in regression analysis that provide a safeguard against violations of both the homoscedasticity and independence assumptions. They are essential for drawing reliable inference when these assumptions are challenged.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ab-testing-explained.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="diving-into-spatial-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/04-lm.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
